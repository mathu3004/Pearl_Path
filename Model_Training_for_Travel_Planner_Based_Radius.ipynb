{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmx0VN3Tloz7ZsJTsTq3tj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathu3004/Pearl_Path/blob/Personalized_Itinerary_Generator_Based_Radius/Model_Training_for_Travel_Planner_Based_Radius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, MultiLabelBinarizer\n",
        "from geopy.geocoders import Nominatim\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hGHTkNPuyLyT",
        "outputId": "8bb5d965-1f57-4483-945e-003d39a27be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1FOuJR9yKR4"
      },
      "outputs": [],
      "source": [
        "# Restaurants Data Preprocessed\n",
        "# Load the merged CSV file\n",
        "file_path = '/content/drive/My Drive/Colombo/FinalPreprocessedMergedRestaurants.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 1. Address Preprocessing\n",
        "# Geocode to latitude and longitude (if needed)\n",
        "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
        "def get_coordinates(address):\n",
        "    try:\n",
        "        location = geolocator.geocode(address)\n",
        "        return location.latitude, location.longitude\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "# Uncomment if geocoding is needed\n",
        "#df['latitude'], df['longitude'] = zip(*df['address'].apply(get_coordinates))\n",
        "\n",
        "# 2. Category Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
        "\n",
        "# 5. Multi-Label Columns Preprocessing\n",
        "def process_list_columns(column):\n",
        "    return column.apply(lambda x: [item.strip() for item in str(x).split(',')] if pd.notnull(x) else [])\n",
        "\n",
        "# Step 1: Create a mapping dictionary for city grouping\n",
        "city_mapping = {\n",
        "    # Map to Nuwara Eliya\n",
        "    'Kotmale': 'Nuwara Eliya',\n",
        "    'Nanu Oya': 'Nuwara Eliya',\n",
        "    'Ramboda': 'Nuwara Eliya',\n",
        "    'Talawakele': 'Nuwara Eliya',\n",
        "    'Ambewela': 'Nuwara Eliya',\n",
        "\n",
        "    # Map to Ella\n",
        "    'Haputale': 'Ella',\n",
        "    'Bandarawela': 'Ella',\n",
        "    'Kithalella': 'Ella',\n",
        "    'Wellawaya': 'Ella',\n",
        "\n",
        "    # Map to Kandy\n",
        "    'Peradeniya': 'Kandy',\n",
        "    'Gampola': 'Kandy',\n",
        "    'Kadugannawa': 'Kandy',\n",
        "    'Tennekumbura': 'Kandy',\n",
        "\n",
        "    # Map to Colombo\n",
        "    'Kadawata': 'Colombo',\n",
        "    'Maharagama': 'Colombo',\n",
        "    'Wattala': 'Colombo',\n",
        "    'Kaduwela': 'Colombo',\n",
        "    'Rajagiriya': 'Colombo',\n",
        "    'Battaramulla': 'Colombo',\n",
        "    'Dehiwala-Mount Lavinia': 'Colombo',\n",
        "    'Nugegoda': 'Colombo',\n",
        "    'Mount Lavinia': 'Colombo',\n",
        "    'Uswetakeiyawa': 'Colombo',\n",
        "    'Boralesgamuwa': 'Colombo',\n",
        "    'Malabe': 'Colombo',\n",
        "    'Thalawathugoda': 'Colombo',\n",
        "    'Dehiwala': 'Colombo',\n",
        "    'Kelaniya': 'Colombo',\n",
        "    'Kiribathgoda': 'Colombo',\n",
        "    'Panadura': 'Colombo'\n",
        "}\n",
        "\n",
        "# Apply the city mapping to create a permanent city column\n",
        "df['city'] = df['addressobj_city'].replace(city_mapping)\n",
        "\n",
        "# Ensure all other cities are labeled correctly\n",
        "df['city'] = df['city'].apply(lambda x: x if x in ['Nuwara Eliya', 'Ella', 'Kandy', 'Colombo'] else 'Other')\n",
        "\n",
        "# 3. One-Hot Encoding to create only four main city columns\n",
        "city_dummies = pd.get_dummies(df['city'], prefix='city')[['city_Colombo', 'city_Ella', 'city_Kandy', 'city_Nuwara Eliya']].astype(int)\n",
        "df = pd.concat([df, city_dummies], axis=1)\n",
        "\n",
        "# drop addressobj_city column\n",
        "df.drop(columns=['addressobj_city'], inplace=True)\n",
        "\n",
        "df['cuisines'] = process_list_columns(df['cuisines'])\n",
        "df['features'] = process_list_columns(df['features'])\n",
        "df['dietaryrestrictions'] = process_list_columns(df['dietaryrestrictions'])\n",
        "df['mealtypes'] = process_list_columns(df['mealtypes'])\n",
        "\n",
        "# One-Hot Encoding for multi-label data\n",
        "mlb = MultiLabelBinarizer()\n",
        "# Create DataFrames for one-hot encoded features and add prefix to column names\n",
        "cuisine_df = pd.DataFrame(mlb.fit_transform(df['cuisines']), columns=mlb.classes_, index=df.index)\n",
        "cuisine_df = cuisine_df.add_prefix('cuisine_')  # Add prefix here\n",
        "df = df.join(cuisine_df)\n",
        "\n",
        "feature_df = pd.DataFrame(mlb.fit_transform(df['features']), columns=mlb.classes_, index=df.index)\n",
        "feature_df = feature_df.add_prefix('feature_')  # Add prefix here\n",
        "df = df.join(feature_df)\n",
        "\n",
        "dietary_df = pd.DataFrame(mlb.fit_transform(df['dietaryrestrictions']), columns=mlb.classes_, index=df.index)\n",
        "dietary_df = dietary_df.add_prefix('dietary_')  # Add prefix here\n",
        "df = df.join(dietary_df)\n",
        "\n",
        "mealtype_df = pd.DataFrame(mlb.fit_transform(df['mealtypes']), columns=mlb.classes_, index=df.index)\n",
        "mealtype_df = mealtype_df.add_prefix('mealtype_')  # Add prefix here\n",
        "df = df.join(mealtype_df)\n",
        "\n",
        "# Save the final cleaned data to a new file\n",
        "final_processed_file_path = \"/content/drive/My Drive/DataPre/Restaurants/LastPreprocessedMergedRestaurants.csv\"\n",
        "df.to_csv(final_processed_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data Preprocessing\n",
        "# Load the uploaded file\n",
        "file_path = \"/content/drive/My Drive/DataPre/User/UserInputs.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Generate synthetic 'maximum_distance' column with values ranging from 10km to 50km\n",
        "df['maximum_distance'] = np.random.randint(10, 51, size=len(df))\n",
        "\n",
        "# Define a dictionary to map old column names to new names\n",
        "column_mapping = {\n",
        "    \"name\": \"name\",\n",
        "    \"how_many_people_are_traveling\": \"peoplecount\",\n",
        "    \"destination\": \"destination\",\n",
        "    \"number_of_days\": \"numberofdays\",\n",
        "    \"what_is_your_age_category\": \"agecategory\",\n",
        "    \"accomadation_type\": \"accomadation_type\",\n",
        "    \"budget_per_day\": \"budget_per_day\",\n",
        "    \"food_preference\": \"food_preference\",\n",
        "    \"cuisine_preference\": \"cuisine_preference\",\n",
        "    \"activities_preference\": \"activities_preference\",\n",
        "    \"time_preference_activities\": \"time_preference_activities\",\n",
        "    \"which_transportation_modes_are_you_preferred_for_traveling_within_the_destination\": \"transportation_mode\",\n",
        "    \"children_or_pets\": \"children_or_pets\",\n",
        "    \"maximum_distance\": \"maximum_distance\"\n",
        "}\n",
        "\n",
        "# Select and rename columns in one step using the dictionary\n",
        "df = df.rename(columns=column_mapping)[column_mapping.values()]\n",
        "\n",
        "# Dropping unnecessary columns if they exist in the dataset\n",
        "columns_to_drop = [\n",
        "    \"do_you_wish_to_have_a_trip_itinerary_generator_website_for_your_future_trips\",\n",
        "    \"is_there_anything_else_you_would_like_us_to_know_about_your_travel_preferences\"\n",
        "]\n",
        "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Convert \"budget_per_day\" ranges into numerical values (average of range)\n",
        "def convert_budget_to_numeric(budget):\n",
        "    budget = str(budget).replace('Rs.', '').strip()  # Remove 'Rs.' prefix\n",
        "    match = re.findall(r'\\d+', budget.replace(',', ''))\n",
        "    if len(match) == 2:\n",
        "        return (int(match[0]) + int(match[1])) / 2\n",
        "    elif len(match) == 1:\n",
        "        return int(match[0])\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "df['budget_per_day'] = df['budget_per_day'].apply(convert_budget_to_numeric)\n",
        "\n",
        "# Reapplying preprocessing with multi-label splitting and one-hot encoding for specific columns\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Define multi-label columns for special encoding\n",
        "multi_label_columns = [\n",
        "    \"cuisine_preference\",\n",
        "    \"activities_preference\",\n",
        "    \"time_preference_activities\",\n",
        "    \"transportation_mode\",\n",
        "    \"peoplecount\",\n",
        "    \"destination\",\n",
        "    \"agecategory\",\n",
        "    \"accomadation_type\",\n",
        "    \"food_preference\",\n",
        "    \"children_or_pets\"\n",
        "]\n",
        "\n",
        "# Split multi-label columns into lists\n",
        "for column in multi_label_columns:\n",
        "    df[column] = df[column].apply(lambda x: [item.strip() for item in str(x).split(',')])\n",
        "\n",
        "# Apply MultiLabelBinarizer to each multi-label column\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "multi_label_encoded_data = pd.DataFrame()\n",
        "\n",
        "for column in multi_label_columns:\n",
        "    # One-hot encode the multi-label columns\n",
        "    encoded = pd.DataFrame(mlb.fit_transform(df[column]),\n",
        "                           columns=[f\"{column}_{cls}\" for cls in mlb.classes_],\n",
        "                           index=df.index)\n",
        "    multi_label_encoded_data = pd.concat([multi_label_encoded_data, encoded], axis=1)\n",
        "\n",
        "# Drop the original multi-label columns from filtered data\n",
        "df = df.drop(columns=multi_label_columns)\n",
        "\n",
        "# Combine the multi-label encoded columns with the rest of the encoded data\n",
        "df = pd.concat([df, multi_label_encoded_data], axis=1)\n",
        "\n",
        "# Save the updated file back to Google Drive\n",
        "file_path = \"/content/drive/My Drive/DataPre/User/PreprocessedUserInputs.csv\"\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "print(\"File successfully saved!\")"
      ],
      "metadata": {
        "id": "xBpRqSKT0N14",
        "outputId": "92dc54b9-cc10-4b6c-a633-1ba2dff05212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Attraction Preprocessing\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List of folder paths where the CSVs are stored\n",
        "folders = [\n",
        "    \"/content/drive/My Drive/DataPre/Attractions\"\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Iterate over each folder and read only CSV files that start with \"Attractions\"\n",
        "for folder in folders:\n",
        "    csv_files = glob.glob(os.path.join(folder, \"Attractions*.csv\"))  # Corrected file pattern\n",
        "\n",
        "    for file in csv_files:\n",
        "        df = pd.read_csv(file)  # Read CSV\n",
        "        dataframes.append(df)   # Append DataFrame to the list\n",
        "\n",
        "# Concatenate all DataFrames into a single one\n",
        "merged_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Save the merged DataFrame as a CSV\n",
        "merged_file_path = \"/content/drive/My Drive/DataPre/Attractions/MergedAttractions.csv\"\n",
        "merged_df.to_csv(merged_file_path, index=False)\n",
        "\n",
        "# Load the uploaded file\n",
        "file_path = \"/content/drive/My Drive/DataPre/Attractions/MergedAttractions.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "def clean_and_process_df(df):\n",
        "    # Standardize column names\n",
        "    df.columns = [col.strip().lower().replace(' ', '').replace('/', '') for col in df.columns]\n",
        "\n",
        "    # Define the required columns\n",
        "    required_columns = [\n",
        "        'name', 'address', 'addressobjcity', 'category',\n",
        "        'latitude', 'longitude', 'rankingposition',\n",
        "        'rating', 'offergrouplowestprice', 'weburl'\n",
        "    ]\n",
        "\n",
        "    # Include subcategories and subtype columns dynamically\n",
        "    subcategory_columns = [f'subcategories{i}' for i in range(10)]\n",
        "    subtype_columns = [f'subtype{i}' for i in range(46)]\n",
        "\n",
        "    all_required_columns = required_columns + subcategory_columns + subtype_columns\n",
        "\n",
        "    # Drop columns that are not in the required columns list and create a copy\n",
        "    df = df[[col for col in df.columns if col in all_required_columns]].copy()\n",
        "\n",
        "    # Combine subcategories and subtype columns into separate columns\n",
        "    subcategory_columns = [col for col in df.columns if col.startswith('subcategories')]\n",
        "    subtype_columns = [col for col in df.columns if col.startswith('subtype')]\n",
        "\n",
        "    # Concatenate subcategories into 'SubCategory' column, excluding NaN values\n",
        "    df['SubCategory'] = df[subcategory_columns].apply(\n",
        "        lambda row: ', '.join([str(x) for x in row if pd.notna(x) and x and x.lower() != 'none']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Concatenate subtypes into 'Subtype' column, excluding NaN values\n",
        "    df['Subtype'] = df[subtype_columns].apply(\n",
        "        lambda row: ', '.join([str(x) for x in row if pd.notna(x) and x and x.lower() != 'none']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Drop the original subcategory and subtype columns to clean up\n",
        "    df.drop(columns=subcategory_columns + subtype_columns, inplace=True)\n",
        "\n",
        "    # Rename columns as specified\n",
        "    df = df.rename(columns={\n",
        "        'name': 'Name',\n",
        "        'address': 'Address',\n",
        "        'addressobjcity': 'City',\n",
        "        'category': 'Category',\n",
        "        'latitude': 'Latitude',\n",
        "        'longitude': 'Longitude',\n",
        "        'rankingposition': 'Ranking_Position',\n",
        "        'rating': 'Rating',\n",
        "        'offergrouplowestprice': 'Lowest Price',\n",
        "        'weburl': 'Web URL'\n",
        "    })\n",
        "\n",
        "    # Fill missing values using .loc to avoid SettingWithCopyWarning\n",
        "    # Convert Ranking_Position to numeric, fill missing with the mode\n",
        "    df['Ranking_Position'] = pd.to_numeric(df['Ranking_Position'], errors='coerce')\n",
        "    mode_value = df['Ranking_Position'].mode()[0] if not df['Ranking_Position'].mode().empty else 0\n",
        "    df['Ranking_Position'] = df['Ranking_Position'].fillna(mode_value)\n",
        "    #drop if it no longitude no latitude\n",
        "    df = df[~df['Latitude'].isin([np.NaN]) & ~df['Longitude'].isin([np.NaN]) & ~df['City'].isin([np.NaN])]\n",
        "\n",
        "    # Convert the 'Lowest Price' to LKR if it is in USD\n",
        "    def convert_to_lkr(price):\n",
        "        if isinstance(price, str) and price.startswith('$'):\n",
        "            try:\n",
        "                usd_value = float(price.replace('$', '').strip())\n",
        "                lkr_value = usd_value * 320  # Convert USD to LKR\n",
        "                return round(lkr_value, 2)   # Keep as float with 2 decimal points\n",
        "            except ValueError:\n",
        "                return np.nan  # Return NaN for invalid prices\n",
        "        try:\n",
        "            # If the price is already in LKR, convert it to a float\n",
        "            return float(price)\n",
        "        except ValueError:\n",
        "            return np.nan  # Return NaN if conversion fails\n",
        "\n",
        "    # Apply the conversion to the 'Lowest Price' column\n",
        "    df['Lowest Price'] = df['Lowest Price'].apply(convert_to_lkr)\n",
        "\n",
        "    # Calculate the mode of the 'Lowest Price' column\n",
        "    mode_price = df['Lowest Price'].mode()[0] if not df['Lowest Price'].mode().empty else 'No price mentioned'\n",
        "\n",
        "    # Fill missing values with the mode value\n",
        "    df['Lowest Price'] = df['Lowest Price'].fillna(mode_price)\n",
        "\n",
        "    # Generate a random duration between 1 to 4 hours\n",
        "    df['Duration'] = np.random.choice([1, 2, 3, 4], size=len(df))\n",
        "\n",
        "    # Define city mappings based on the provided criteria\n",
        "    city_mapping = {\n",
        "        'Peradeniya': 'Kandy',\n",
        "        'Gampola': 'Kandy',\n",
        "        'Pussellawa': 'Kandy',\n",
        "        'Heeloya': 'Kandy',\n",
        "        'Gurudeniya': 'Kandy',\n",
        "        'Pilimathalawa': 'Kandy',\n",
        "        'Murutalawa': 'Kandy',\n",
        "\n",
        "        'Badulla': 'Ella',\n",
        "        'Nanu Oya': 'Ella',\n",
        "        'Demodara': 'Ella',\n",
        "        'Kalupahana': 'Ella',\n",
        "        'Bandarawela': 'Ella',\n",
        "        'Ambagollapathana': 'Ella',\n",
        "\n",
        "        'Hatton': 'Nuwara Eliya',\n",
        "\n",
        "        'Negombo': 'Colombo',\n",
        "        'Wattala': 'Colombo',\n",
        "        'Katunayaka': 'Colombo',\n",
        "        'Kaduwela': 'Colombo',\n",
        "        'Katunayake': 'Colombo'\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the 'City' column\n",
        "    df['City'] = df['City'].apply(lambda x: city_mapping.get(x, x))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Clean and process the merged dataset\n",
        "df = clean_and_process_df(merged_df)\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Multi-label encoding for 'City', 'SubCategory', and 'Subtype' columns\n",
        "def multi_label_encoding(df, columns):\n",
        "    for column in columns:\n",
        "        mlb = MultiLabelBinarizer()\n",
        "        # Split by comma, strip whitespace, and handle empty strings\n",
        "        encoded_data = mlb.fit_transform(df[column].apply(lambda x: [item.strip() for item in str(x).split(',') if item.strip()]))\n",
        "        encoded_df = pd.DataFrame(encoded_data, columns=[f\"{column}_{cls}\" for cls in mlb.classes_])\n",
        "        df = pd.concat([df, encoded_df], axis=1)\n",
        "    return df\n",
        "\n",
        "# One-hot encoding for 'Category' column\n",
        "def category_encoding(df, column):\n",
        "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "    # Apply OneHotEncoder\n",
        "    encoded_data = ohe.fit_transform(df[[column]])\n",
        "\n",
        "    # Generate column names dynamically based on categories\n",
        "    category_columns = [f\"{column}_{cls}\" for cls in ohe.categories_[0]]\n",
        "\n",
        "    # Ensure the shape of data matches the expected columns\n",
        "    encoded_df = pd.DataFrame(encoded_data, columns=category_columns, index=df.index)\n",
        "\n",
        "    # Concatenate the encoded data with the original DataFrame\n",
        "    df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply multi-label encoding\n",
        "multi_label_columns = ['City', 'SubCategory', 'Subtype']\n",
        "df = multi_label_encoding(df, multi_label_columns)\n",
        "\n",
        "# Apply category encoding\n",
        "df = category_encoding(df, 'Category')\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV file\n",
        "output_file = '/content/drive/My Drive/DataPre/Attractions/PreprocessedMergedAttractions.csv'\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Processing complete. Cleaned data saved to '{output_file}'\")"
      ],
      "metadata": {
        "id": "KQljhu9-4mq_",
        "outputId": "0e7c5216-ab32-48df-c514-3260d1b1bf20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Processing complete. Cleaned data saved to '/content/drive/My Drive/DataPre/Attractions/PreprocessedMergedAttractions.csv'\n"
          ]
        }
      ]
    }
  ]
}