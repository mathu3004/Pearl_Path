{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeYqWFe54VpRgsTIC0CjJc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathu3004/Pearl_Path/blob/Personalized_Itinerary_Generator_Based_Radius/Model_Training_for_Travel_Planner_Based_Radius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, MultiLabelBinarizer\n",
        "from geopy.geocoders import Nominatim\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hGHTkNPuyLyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1FOuJR9yKR4"
      },
      "outputs": [],
      "source": [
        "# Restaurants Data Preprocessed\n",
        "# Load the merged CSV file\n",
        "file_path = '/content/drive/My Drive/Colombo/FinalPreprocessedMergedRestaurants.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 1. Address Preprocessing\n",
        "# Geocode to latitude and longitude (if needed)\n",
        "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
        "def get_coordinates(address):\n",
        "    try:\n",
        "        location = geolocator.geocode(address)\n",
        "        return location.latitude, location.longitude\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "# Uncomment if geocoding is needed\n",
        "#df['latitude'], df['longitude'] = zip(*df['address'].apply(get_coordinates))\n",
        "\n",
        "# 2. Category Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
        "\n",
        "'''# 3. Review and Ranking\n",
        "df['numberofreviews'] = df['numberofreviews'].fillna(0)\n",
        "df['rankingposition'] = df['rankingposition'].fillna(df['rankingposition'].median())\n",
        "df['rankingdenominator'] = df['rankingdenominator'].fillna(1)\n",
        "\n",
        "# Calculate ranking percentage\n",
        "df['ranking_percentage'] = df['rankingposition'] / df['rankingdenominator']\n",
        "\n",
        "# Extract numerical data from ranking string\n",
        "df['ranking_position'] = df['rankingstring'].str.extract(r'#(\\d+)').astype(float)\n",
        "df['ranking_total'] = df['rankingstring'].str.extract(r'of (\\d+)').astype(float)\n",
        "df['ranking_normalized'] = df['ranking_position'] / df['ranking_total']\n",
        "\n",
        "# 4. Rating Normalization\n",
        "scaler = MinMaxScaler()\n",
        "df['rating'] = df['rating'].fillna(df['rating'].median())\n",
        "df['rawranking'] = df['rawranking'].fillna(df['rawranking'].median())\n",
        "df[['rating', 'rawranking']] = scaler.fit_transform(df[['rating', 'rawranking']])'''\n",
        "\n",
        "# 5. Multi-Label Columns Preprocessing\n",
        "def process_list_columns(column):\n",
        "    return column.apply(lambda x: [item.strip() for item in str(x).split(',')] if pd.notnull(x) else [])\n",
        "\n",
        "# Step 1: Create a mapping dictionary for city grouping\n",
        "city_mapping = {\n",
        "    # Map to Nuwara Eliya\n",
        "    'Kotmale': 'Nuwara Eliya',\n",
        "    'Nanu Oya': 'Nuwara Eliya',\n",
        "    'Ramboda': 'Nuwara Eliya',\n",
        "    'Talawakele': 'Nuwara Eliya',\n",
        "    'Ambewela': 'Nuwara Eliya',\n",
        "\n",
        "    # Map to Ella\n",
        "    'Haputale': 'Ella',\n",
        "    'Bandarawela': 'Ella',\n",
        "    'Kithalella': 'Ella',\n",
        "    'Wellawaya': 'Ella',\n",
        "\n",
        "    # Map to Kandy\n",
        "    'Peradeniya': 'Kandy',\n",
        "    'Gampola': 'Kandy',\n",
        "    'Kadugannawa': 'Kandy',\n",
        "    'Tennekumbura': 'Kandy',\n",
        "\n",
        "    # Map to Colombo\n",
        "    'Kadawata': 'Colombo',\n",
        "    'Maharagama': 'Colombo',\n",
        "    'Wattala': 'Colombo',\n",
        "    'Kaduwela': 'Colombo',\n",
        "    'Rajagiriya': 'Colombo',\n",
        "    'Battaramulla': 'Colombo',\n",
        "    'Dehiwala-Mount Lavinia': 'Colombo',\n",
        "    'Nugegoda': 'Colombo',\n",
        "    'Mount Lavinia': 'Colombo',\n",
        "    'Uswetakeiyawa': 'Colombo',\n",
        "    'Boralesgamuwa': 'Colombo',\n",
        "    'Malabe': 'Colombo',\n",
        "    'Thalawathugoda': 'Colombo',\n",
        "    'Dehiwala': 'Colombo',\n",
        "    'Kelaniya': 'Colombo',\n",
        "    'Kiribathgoda': 'Colombo',\n",
        "    'Panadura': 'Colombo'\n",
        "}\n",
        "\n",
        "# Apply the city mapping to create a permanent city column\n",
        "df['city'] = df['addressobj_city'].replace(city_mapping)\n",
        "\n",
        "# Ensure all other cities are labeled correctly\n",
        "df['city'] = df['city'].apply(lambda x: x if x in ['Nuwara Eliya', 'Ella', 'Kandy', 'Colombo'] else 'Other')\n",
        "\n",
        "# 3. One-Hot Encoding to create only four main city columns\n",
        "city_dummies = pd.get_dummies(df['city'], prefix='city')[['city_Colombo', 'city_Ella', 'city_Kandy', 'city_Nuwara Eliya']].astype(int)\n",
        "df = pd.concat([df, city_dummies], axis=1)\n",
        "\n",
        "# drop addressobj_city column\n",
        "df.drop(columns=['addressobj_city'], inplace=True)\n",
        "\n",
        "df['cuisines'] = process_list_columns(df['cuisines'])\n",
        "df['features'] = process_list_columns(df['features'])\n",
        "df['dietaryrestrictions'] = process_list_columns(df['dietaryrestrictions'])\n",
        "df['mealtypes'] = process_list_columns(df['mealtypes'])\n",
        "\n",
        "# One-Hot Encoding for multi-label data\n",
        "mlb = MultiLabelBinarizer()\n",
        "# Create DataFrames for one-hot encoded features and add prefix to column names\n",
        "cuisine_df = pd.DataFrame(mlb.fit_transform(df['cuisines']), columns=mlb.classes_, index=df.index)\n",
        "cuisine_df = cuisine_df.add_prefix('cuisine_')  # Add prefix here\n",
        "df = df.join(cuisine_df)\n",
        "\n",
        "feature_df = pd.DataFrame(mlb.fit_transform(df['features']), columns=mlb.classes_, index=df.index)\n",
        "feature_df = feature_df.add_prefix('feature_')  # Add prefix here\n",
        "df = df.join(feature_df)\n",
        "\n",
        "dietary_df = pd.DataFrame(mlb.fit_transform(df['dietaryrestrictions']), columns=mlb.classes_, index=df.index)\n",
        "dietary_df = dietary_df.add_prefix('dietary_')  # Add prefix here\n",
        "df = df.join(dietary_df)\n",
        "\n",
        "mealtype_df = pd.DataFrame(mlb.fit_transform(df['mealtypes']), columns=mlb.classes_, index=df.index)\n",
        "mealtype_df = mealtype_df.add_prefix('mealtype_')  # Add prefix here\n",
        "df = df.join(mealtype_df)\n",
        "\n",
        "# Save the final cleaned data to a new file\n",
        "final_processed_file_path = \"/content/drive/My Drive/Colombo/LastPreprocessedMergedRestaurants.csv\"\n",
        "df.to_csv(final_processed_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data Preprocessing\n",
        "# Load the uploaded file\n",
        "file_path = \"/content/drive/My Drive/DataPre/preprocessed_user_inputs.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Generate synthetic 'maximum_distance' column with values ranging from 10km to 50km\n",
        "df['maximum_distance'] = np.random.randint(10, 51, size=len(df))\n",
        "\n",
        "# Save the updated file back to Google Drive\n",
        "file_path = \"/content/drive/My Drive/DataPre/preprocessed_user_inputs.csv\"\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "print(\"File successfully saved!\")"
      ],
      "metadata": {
        "id": "xBpRqSKT0N14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}