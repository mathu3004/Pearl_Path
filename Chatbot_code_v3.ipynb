{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVFJTBzfJsj/FuhI7nYfz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathu3004/Pearl_Path/blob/Chatbot/Chatbot_code_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22pbGveEayVL",
        "outputId": "23a92896-bcac-49fa-cee1-64b30e440758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.11.2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0dev,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.0dev,>=13.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (14.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0dev,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.12.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.1->google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.1->google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.1->google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.1->google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0dev,>=0.28.1->google-genai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0dev,>=0.28.1->google-genai) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo\n",
        "!pip install requests\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install google-genai\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install nltk\n",
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "from pymongo import MongoClient\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import requests\n",
        "from transformers import DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "# Initialize MongoDB client\n",
        "client = MongoClient('mongodb+srv://Pearlpath:DMEN2425@pearlpath.lq9jq.mongodb.net/?retryWrites=true&w=majority&appName=PearlPath')\n",
        "plan_db = client['itineraries']\n",
        "hotel_db = client['Hotels']\n",
        "attraction_db = client['Attractions']\n",
        "restaurant_db = client['Restaurants']\n",
        "\n",
        "# Initialize DPR models and tokenizers\n",
        "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "\n",
        "# Initialize T5 model and tokenizer\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "def greet_user():\n",
        "    return \"Hello! Welcome to the trip itinerary chatbot. Please provide your unique user ID to get started.\"\n",
        "\n",
        "def get_user_id():\n",
        "    user_id = input(\"Please enter your unique user ID: \")\n",
        "    return user_id\n",
        "\n",
        "def detect_keywords(user_input):\n",
        "    keywords = {\n",
        "        'action': None,\n",
        "        'item_type': None,\n",
        "        'similarity': False,\n",
        "        'info_request': False,\n",
        "        'emergency': False,\n",
        "        'display_itinerary': False\n",
        "    }\n",
        "    if 'remove' in user_input.lower():\n",
        "        keywords['action'] = 'remove'\n",
        "    if 'add' in user_input.lower():\n",
        "        keywords['action'] = 'add'\n",
        "    if 'hotel' in user_input.lower():\n",
        "        keywords['item_type'] = 'hotel'\n",
        "    if 'attraction' in user_input.lower():\n",
        "        keywords['item_type'] = 'attraction'\n",
        "    if 'restaurant' in user_input.lower():\n",
        "        keywords['item_type'] = 'restaurant'\n",
        "    if 'similar' in user_input.lower():\n",
        "        keywords['similarity'] = True\n",
        "    if any(keyword in user_input.lower() for keyword in ['contact', 'email', 'phone', 'website', 'information']):\n",
        "        keywords['info_request'] = True\n",
        "    if any(keyword in user_input.lower() for keyword in ['emergency', 'hospital', 'police', 'embassy', 'cpr']):\n",
        "        keywords['emergency'] = True\n",
        "    if 'display' in user_input.lower() or 'show' in user_input.lower():\n",
        "        keywords['display_itinerary'] = True\n",
        "    return keywords\n",
        "\n",
        "def retrieve_itinerary(user_id, plan_id):\n",
        "    try:\n",
        "        itinerary = plan_db.find_one({'user_id': user_id, 'plan_id': plan_id})\n",
        "        if not itinerary:\n",
        "            return None\n",
        "        return itinerary\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving itinerary: {e}\"\n",
        "\n",
        "def find_similar_item(item_type, current_item):\n",
        "    try:\n",
        "        if item_type == 'hotel':\n",
        "            similar_items = hotel_db.find({'location': current_item['location'], 'price_range': current_item['price_range']})\n",
        "        elif item_type == 'attraction':\n",
        "            similar_items = attraction_db.find({'location': current_item['location'], 'type': current_item['type']})\n",
        "        elif item_type == 'restaurant':\n",
        "            similar_items = restaurant_db.find({'location': current_item['location'], 'cuisine': current_item['cuisine']})\n",
        "        return list(similar_items)\n",
        "    except Exception as e:\n",
        "        return f\"Error finding similar item: {e}\"\n",
        "\n",
        "def update_itinerary(user_id, plan_id, action, item_type, similar_item=None):\n",
        "    try:\n",
        "        itinerary = retrieve_itinerary(user_id, plan_id)\n",
        "        if not itinerary:\n",
        "            return \"No itinerary found for the given user ID and plan ID.\"\n",
        "\n",
        "        if action == 'remove':\n",
        "            if item_type in itinerary:\n",
        "                del itinerary[item_type]\n",
        "                plan_db.update_one({'user_id': user_id, 'plan_id': plan_id}, {'$set': itinerary})\n",
        "                return f\"{item_type.capitalize()} removed from your itinerary.\"\n",
        "            else:\n",
        "                return f\"No {item_type} found in your itinerary.\"\n",
        "\n",
        "        if action == 'add' and similar_item:\n",
        "            itinerary[item_type] = similar_item\n",
        "            plan_db.update_one({'user_id': user_id, 'plan_id': plan_id}, {'$set': itinerary})\n",
        "            return f\"Similar {item_type} added to your itinerary.\"\n",
        "\n",
        "        return \"Unable to update itinerary.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error updating itinerary: {e}\"\n",
        "\n",
        "def search_database(item_type, item_name):\n",
        "    try:\n",
        "        if item_type == 'hotel':\n",
        "            return hotel_db.find_one({'name': item_name})\n",
        "        elif item_type == 'attraction':\n",
        "            return attraction_db.find_one({'name': item_name})\n",
        "        elif item_type == 'restaurant':\n",
        "            return restaurant_db.find_one({'name': item_name})\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        return f\"Error searching database: {e}\"\n",
        "\n",
        "def web_search(query):\n",
        "    try:\n",
        "        # Perform a web search using the Gemini API\n",
        "        client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "        model = \"gemini-2.0-flash\"\n",
        "        contents = [\n",
        "            types.Content(\n",
        "                role=\"user\",\n",
        "                parts=[\n",
        "                    types.Part.from_text(text=query),\n",
        "                ],\n",
        "            ),\n",
        "        ]\n",
        "        generate_content_config = types.GenerateContentConfig(\n",
        "            temperature=1,\n",
        "            top_p=0.95,\n",
        "            top_k=40,\n",
        "            max_output_tokens=8192,\n",
        "            response_mime_type=\"text/plain\",\n",
        "        )\n",
        "\n",
        "        response = \"\"\n",
        "        for chunk in client.models.generate_content_stream(\n",
        "            model=model,\n",
        "            contents=contents,\n",
        "            config=generate_content_config,\n",
        "        ):\n",
        "            response += chunk.text\n",
        "\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"Error performing web search: {e}\"\n",
        "\n",
        "def handle_info_request(item_type, item_name):\n",
        "    try:\n",
        "        item = search_database(item_type, item_name)\n",
        "        if item:\n",
        "            return f\"Contact information for {item_name}: Email: {item.get('email')}, Phone: {item.get('phone')}, Website: {item.get('website')}\"\n",
        "        else:\n",
        "            query = f\"contact information for {item_name} {item_type}\"\n",
        "            return web_search(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error handling information request: {e}\"\n",
        "\n",
        "def handle_emergency_request(user_input):\n",
        "    try:\n",
        "        location = get_user_location()\n",
        "        if not location:\n",
        "            return \"Unable to determine your location. Please try again later.\"\n",
        "\n",
        "        if 'hospital' in user_input.lower():\n",
        "            query = f\"nearest hospital in {location}\"\n",
        "        elif 'police' in user_input.lower():\n",
        "            query = f\"nearest police station in {location}\"\n",
        "        elif 'embassy' in user_input.lower():\n",
        "            query = f\"nearest embassy in {location}\"\n",
        "        elif 'cpr' in user_input.lower():\n",
        "            query = \"how to perform CPR\"\n",
        "        else:\n",
        "            return \"Please specify the type of emergency assistance you need.\"\n",
        "\n",
        "        return web_search(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error handling emergency request: {e}\"\n",
        "\n",
        "def get_user_location():\n",
        "    try:\n",
        "        # Placeholder for actual location retrieval logic\n",
        "        response = requests.get('https://api.ipgeolocation.io/ipgeo', params={'apiKey': 'your_actual_location_api_key_here'})\n",
        "        data = response.json()\n",
        "        return f\"{data['city']}, {data['country_name']}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving location: {e}\"\n",
        "\n",
        "def retrieve_documents(query, documents):\n",
        "    # Encode the query and documents using DPR\n",
        "    query_embedding = question_encoder(**question_tokenizer(query, return_tensors='pt'))[0]\n",
        "    document_embeddings = context_encoder(**context_tokenizer(documents, return_tensors='pt', padding=True, truncation=True))[0]\n",
        "\n",
        "    # Compute similarity scores\n",
        "    similarity_scores = torch.matmul(query_embedding, document_embeddings.T)\n",
        "    k = min(5, len(documents))  # Ensure k does not exceed the number of documents\n",
        "    top_documents = similarity_scores.topk(k).indices\n",
        "\n",
        "    return [documents[i] for i in top_documents]\n",
        "\n",
        "def generate_response(query, retrieved_documents):\n",
        "    # Concatenate the query and retrieved documents\n",
        "    input_text = query + \" \".join(retrieved_documents)\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    # Generate the response using T5\n",
        "    output_ids = t5_model.generate(input_ids)\n",
        "    response = t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return response\n",
        "\n",
        "def handle_user_request(user_input, user_id, plan_id):\n",
        "    try:\n",
        "        keywords = detect_keywords(user_input)\n",
        "        itinerary = retrieve_itinerary(user_id, plan_id)\n",
        "\n",
        "        if not itinerary:\n",
        "            return \"No itinerary found for the given user ID and plan ID.\"\n",
        "\n",
        "        if keywords['display_itinerary']:\n",
        "            return f\"Your itinerary: {itinerary}\"\n",
        "\n",
        "        if keywords['action'] == 'remove':\n",
        "            return update_itinerary(user_id, plan_id, 'remove', keywords['item_type'])\n",
        "\n",
        "        if keywords['action'] == 'add' and keywords['similarity']:\n",
        "            current_item = itinerary.get(keywords['item_type'])\n",
        "            if current_item:\n",
        "                similar_items = find_similar_item(keywords['item_type'], current_item)\n",
        "                if similar_items:\n",
        "                    similar_item = similar_items[0]  # For simplicity, taking the first similar item\n",
        "                    return update_itinerary(user_id, plan_id, 'add', keywords['item_type'], similar_item)\n",
        "                else:\n",
        "                    return f\"No similar {keywords['item_type']} found.\"\n",
        "            else:\n",
        "                return f\"No current {keywords['item_type']} found in your itinerary.\"\n",
        "\n",
        "        if keywords['info_request']:\n",
        "            item_name = re.search(r'for (.+?) (hotel|attraction|restaurant)', user_input.lower())\n",
        "            if item_name:\n",
        "                item_name = item_name.group(1)\n",
        "                item_type = item_name.group(2)\n",
        "                return handle_info_request(item_type, item_name)\n",
        "            else:\n",
        "                return \"Please specify the name of the hotel, attraction, or restaurant you are looking for.\"\n",
        "\n",
        "        if keywords['emergency']:\n",
        "            return handle_emergency_request(user_input)\n",
        "\n",
        "        return \"Unable to process your request.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error handling user request: {e}\"\n",
        "\n",
        "def evaluate_retrieval(query, relevant_docs, retrieved_docs, k=5):\n",
        "    # Calculate Precision@k, Recall@k, and F1 Score\n",
        "    relevant_set = set(relevant_docs)\n",
        "    retrieved_set = set(retrieved_docs[:k])\n",
        "\n",
        "    precision = len(relevant_set.intersection(retrieved_set)) / len(retrieved_set)\n",
        "    recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_generation(reference, generated):\n",
        "    # Calculate BLEU Score\n",
        "    smooth = SmoothingFunction().method4\n",
        "    bleu_score = sentence_bleu([reference.split()], generated.split(), smoothing_function=smooth)\n",
        "\n",
        "    # Calculate ROUGE Score\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(generated, reference)[0]\n",
        "\n",
        "    return bleu_score, rouge_scores\n",
        "\n",
        "def visualize_metrics(precision, recall, f1, bleu, rouge):\n",
        "    # Plot Precision, Recall, and F1 Score\n",
        "    metrics = {'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
        "    sns.barplot(x=list(metrics.keys()), y=list(metrics.values()))\n",
        "    plt.title('Retrieval Metrics')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot BLEU and ROUGE Scores\n",
        "    generation_metrics = {'BLEU Score': bleu, 'ROUGE-1': rouge['rouge-1']['f'], 'ROUGE-2': rouge['rouge-2']['f'], 'ROUGE-L': rouge['rouge-l']['f']}\n",
        "    sns.barplot(x=list(generation_metrics.keys()), y=list(generation_metrics.values()))\n",
        "    plt.title('Generation Metrics')\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    print(greet_user())\n",
        "    user_id = get_user_id()\n",
        "    plan_id = input(\"Please enter your plan ID: \")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"How can I assist you with your itinerary? \")\n",
        "        response = handle_user_request(user_input, user_id, plan_id)\n",
        "        print(response)\n",
        "\n",
        "        # Example evaluation (replace with actual data)\n",
        "        relevant_docs = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "        retrieved_docs = retrieve_documents(user_input, relevant_docs)\n",
        "        precision, recall, f1 = evaluate_retrieval(user_input, relevant_docs, retrieved_docs)\n",
        "\n",
        "        reference = \"This is a reference response.\"\n",
        "        bleu, rouge = evaluate_generation(reference, response)\n",
        "\n",
        "        visualize_metrics(precision, recall, f1, bleu, rouge)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "_qpOGw7Va2B8",
        "outputId": "238c3c53-bf4f-461c-836e-5d0552c3c12c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! Welcome to the trip itinerary chatbot. Please provide your unique user ID to get started.\n",
            "Please enter your unique user ID: 123\n",
            "Please enter your plan ID: 123\n",
            "How can I assist you with your itinerary? how to do cpr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error performing web search: Missing key inputs argument! To use the Google AI API,provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "only integer tensors of a single element can be converted to an index",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2a18f736cd66>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-2a18f736cd66>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Example evaluation (replace with actual data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mrelevant_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"doc1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"doc2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"doc3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mretrieved_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieved_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2a18f736cd66>\u001b[0m in \u001b[0;36mretrieve_documents\u001b[0;34m(query, documents)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mtop_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_documents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieved_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2a18f736cd66>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mtop_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_documents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieved_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
          ]
        }
      ]
    }
  ]
}