{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj1x+Od4BAKafHQZAA+dv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathu3004/Pearl_Path/blob/Chatbot/Chatbot_code_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install requests\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install google-genai\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install nltk\n",
        "!pip install rouge"
      ],
      "metadata": {
        "id": "tqnZyo5W_99i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "6SVYBsR9pxlC",
        "outputId": "ba403b6b-fa86-429c-f35c-ce2c07f93ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (1105) must match the size of tensor b (512) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-97ba7b72c735>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_contexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mtrain_context_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/dpr/modeling_dpr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         outputs = self.ctx_encoder(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/dpr/modeling_dpr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     ) -> Union[BaseModelOutputWithPooling, Tuple[Tensor, ...]]:\n\u001b[0;32m--> 180\u001b[0;31m         outputs = self.bert_model(\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1105) must match the size of tensor b (512) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "from pymongo import MongoClient\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import requests\n",
        "from transformers import DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "# Initialize MongoDB client\n",
        "client = MongoClient('mongodb+srv://Pearlpath:DMEN2425@pearlpath.lq9jq.mongodb.net/?retryWrites=true&w=majority&appName=PearlPath')\n",
        "plan_db = client['itineraries']\n",
        "hotel_db = client['Hotels']\n",
        "attraction_db = client['Attractions']\n",
        "restaurant_db = client['Restaurants']\n",
        "\n",
        "# Initialize DPR models and tokenizers\n",
        "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "\n",
        "# Initialize T5 model and tokenizer\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "def greet_user():\n",
        "    return \"Hello! Welcome to the trip itinerary chatbot. Please provide your unique user ID to get started.\"\n",
        "\n",
        "def get_user_id():\n",
        "    user_id = input(\"Please enter your unique user ID: \")\n",
        "    return user_id\n",
        "\n",
        "def detect_keywords(user_input):\n",
        "    keywords = {\n",
        "        'action': None,\n",
        "        'item_type': None,\n",
        "        'similarity': False,\n",
        "        'info_request': False,\n",
        "        'emergency': False,\n",
        "        'display_itinerary': False\n",
        "    }\n",
        "    if 'remove' in user_input.lower():\n",
        "        keywords['action'] = 'remove'\n",
        "    if 'add' in user_input.lower():\n",
        "        keywords['action'] = 'add'\n",
        "    if 'hotel' in user_input.lower():\n",
        "        keywords['item_type'] = 'hotel'\n",
        "    if 'attraction' in user_input.lower():\n",
        "        keywords['item_type'] = 'attraction'\n",
        "    if 'restaurant' in user_input.lower():\n",
        "        keywords['item_type'] = 'restaurant'\n",
        "    if 'similar' in user_input.lower():\n",
        "        keywords['similarity'] = True\n",
        "    if any(keyword in user_input.lower() for keyword in ['contact', 'email', 'phone', 'website', 'information']):\n",
        "        keywords['info_request'] = True\n",
        "    if any(keyword in user_input.lower() for keyword in ['emergency', 'hospital', 'police', 'embassy', 'cpr']):\n",
        "        keywords['emergency'] = True\n",
        "    if 'display' in user_input.lower() or 'show' in user_input.lower():\n",
        "        keywords['display_itinerary'] = True\n",
        "    return keywords\n",
        "\n",
        "def retrieve_itinerary(user_id, plan_id):\n",
        "    try:\n",
        "        itinerary = plan_db.find_one({'user_id': user_id, 'plan_id': plan_id})\n",
        "        if not itinerary:\n",
        "            return None\n",
        "        return itinerary\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving itinerary: {e}\"\n",
        "\n",
        "def find_similar_item(item_type, current_item):\n",
        "    try:\n",
        "        if item_type == 'hotel':\n",
        "            similar_items = hotel_db.find({'location': current_item['location'], 'price_range': current_item['price_range']})\n",
        "        elif item_type == 'attraction':\n",
        "            similar_items = attraction_db.find({'location': current_item['location'], 'type': current_item['type']})\n",
        "        elif item_type == 'restaurant':\n",
        "            similar_items = restaurant_db.find({'location': current_item['location'], 'cuisine': current_item['cuisine']})\n",
        "        return list(similar_items)\n",
        "    except Exception as e:\n",
        "        return f\"Error finding similar item: {e}\"\n",
        "\n",
        "def update_itinerary(user_id, plan_id, action, item_type, similar_item=None):\n",
        "    try:\n",
        "        itinerary = retrieve_itinerary(user_id, plan_id)\n",
        "        if not itinerary:\n",
        "            return \"No itinerary found for the given user ID and plan ID.\"\n",
        "\n",
        "        if action == 'remove':\n",
        "            if item_type in itinerary:\n",
        "                del itinerary[item_type]\n",
        "                plan_db.update_one({'user_id': user_id, 'plan_id': plan_id}, {'$set': itinerary})\n",
        "                return f\"{item_type.capitalize()} removed from your itinerary.\"\n",
        "            else:\n",
        "                return f\"No {item_type} found in your itinerary.\"\n",
        "\n",
        "        if action == 'add' and similar_item:\n",
        "            itinerary[item_type] = similar_item\n",
        "            plan_db.update_one({'user_id': user_id, 'plan_id': plan_id}, {'$set': itinerary})\n",
        "            return f\"Similar {item_type} added to your itinerary.\"\n",
        "\n",
        "        return \"Unable to update itinerary.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error updating itinerary: {e}\"\n",
        "\n",
        "def search_database(item_type, item_name):\n",
        "    try:\n",
        "        if item_type == 'hotel':\n",
        "            return hotel_db.find_one({'name': item_name})\n",
        "        elif item_type == 'attraction':\n",
        "            return attraction_db.find_one({'name': item_name})\n",
        "        elif item_type == 'restaurant':\n",
        "            return restaurant_db.find_one({'name': item_name})\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        return f\"Error searching database: {e}\"\n",
        "\n",
        "def web_search(query):\n",
        "    try:\n",
        "        # Perform a web search using the Gemini API\n",
        "        client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "        model = \"gemini-2.0-flash\"\n",
        "        contents = [\n",
        "            types.Content(\n",
        "                role=\"user\",\n",
        "                parts=[\n",
        "                    types.Part.from_text(text=query),\n",
        "                ],\n",
        "            ),\n",
        "        ]\n",
        "        generate_content_config = types.GenerateContentConfig(\n",
        "            temperature=1,\n",
        "            top_p=0.95,\n",
        "            top_k=40,\n",
        "            max_output_tokens=8192,\n",
        "            response_mime_type=\"text/plain\",\n",
        "        )\n",
        "\n",
        "        response = \"\"\n",
        "        for chunk in client.models.generate_content_stream(\n",
        "            model=model,\n",
        "            contents=contents,\n",
        "            config=generate_content_config,\n",
        "        ):\n",
        "            response += chunk.text\n",
        "\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"Error performing web search: {e}\"\n",
        "\n",
        "def handle_info_request(item_type, item_name):\n",
        "    try:\n",
        "        item = search_database(item_type, item_name)\n",
        "        if item:\n",
        "            return f\"Contact information for {item_name}: Email: {item.get('email')}, Phone: {item.get('phone')}, Website: {item.get('website')}\"\n",
        "        else:\n",
        "            query = f\"contact information for {item_name} {item_type}\"\n",
        "            return web_search(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error handling information request: {e}\"\n",
        "\n",
        "def handle_emergency_request(user_input):\n",
        "    try:\n",
        "        location = get_user_location()\n",
        "        if not location:\n",
        "            return \"Unable to determine your location. Please try again later.\"\n",
        "\n",
        "        if 'hospital' in user_input.lower():\n",
        "            query = f\"nearest hospital in {location}\"\n",
        "        elif 'police' in user_input.lower():\n",
        "            query = f\"nearest police station in {location}\"\n",
        "        elif 'embassy' in user_input.lower():\n",
        "            query = f\"nearest embassy in {location}\"\n",
        "        elif 'cpr' in user_input.lower():\n",
        "            query = \"how to perform CPR\"\n",
        "        else:\n",
        "            return \"Please specify the type of emergency assistance you need.\"\n",
        "\n",
        "        return web_search(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error handling emergency request: {e}\"\n",
        "\n",
        "def get_user_location():\n",
        "    try:\n",
        "        # Placeholder for actual location retrieval logic\n",
        "        response = requests.get('https://api.ipgeolocation.io/ipgeo', params={'apiKey': 'your_actual_location_api_key_here'})\n",
        "        data = response.json()\n",
        "        return f\"{data['city']}, {data['country_name']}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving location: {e}\"\n",
        "\n",
        "def retrieve_documents(query, documents):\n",
        "    # Encode the query and documents using DPR\n",
        "    query_embedding = question_encoder(**question_tokenizer(query, return_tensors='pt'))[0]\n",
        "    document_embeddings = context_encoder(**context_tokenizer(documents, return_tensors='pt', padding=True, truncation=True))[0]\n",
        "\n",
        "    # Compute similarity scores\n",
        "    similarity_scores = torch.matmul(query_embedding, document_embeddings.T)\n",
        "    k = min(5, len(documents))  # Ensure k does not exceed the number of documents\n",
        "    top_documents = similarity_scores.topk(k).indices\n",
        "\n",
        "    return [documents[i] for i in top_documents]\n",
        "\n",
        "def generate_response(query, retrieved_documents):\n",
        "    # Concatenate the query and retrieved documents\n",
        "    input_text = query + \" \".join(retrieved_documents)\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    # Generate the response using T5\n",
        "    output_ids = t5_model.generate(input_ids)\n",
        "    response = t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return response\n",
        "\n",
        "def handle_user_request(user_input, user_id, plan_id):\n",
        "    try:\n",
        "        keywords = detect_keywords(user_input)\n",
        "        itinerary = retrieve_itinerary(user_id, plan_id)\n",
        "\n",
        "        if not itinerary:\n",
        "            return \"No itinerary found for the given user ID and plan ID.\"\n",
        "\n",
        "        if keywords['display_itinerary']:\n",
        "            return f\"Your itinerary: {itinerary}\"\n",
        "\n",
        "        if keywords['action'] == 'remove':\n",
        "            return update_itinerary(user_id, plan_id, 'remove', keywords['item_type'])\n",
        "\n",
        "        if keywords['action'] == 'add' and keywords['similarity']:\n",
        "            current_item = itinerary.get(keywords['item_type'])\n",
        "            if current_item:\n",
        "                similar_items = find_similar_item(keywords['item_type'], current_item)\n",
        "                if similar_items:\n",
        "                    similar_item = similar_items[0]  # For simplicity, taking the first similar item\n",
        "                    return update_itinerary(user_id, plan_id, 'add', keywords['item_type'], similar_item)\n",
        "                else:\n",
        "                    return f\"No similar {keywords['item_type']} found.\"\n",
        "            else:\n",
        "                return f\"No current {keywords['item_type']} found in your itinerary.\"\n",
        "\n",
        "        if keywords['info_request']:\n",
        "            item_name = re.search(r'for (.+?) (hotel|attraction|restaurant)', user_input.lower())\n",
        "            if item_name:\n",
        "                item_name = item_name.group(1)\n",
        "                item_type = item_name.group(2)\n",
        "                return handle_info_request(item_type, item_name)\n",
        "            else:\n",
        "                return \"Please specify the name of the hotel, attraction, or restaurant you are looking for.\"\n",
        "\n",
        "        if keywords['emergency']:\n",
        "            return handle_emergency_request(user_input)\n",
        "\n",
        "        return \"Unable to process your request.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error handling user request: {e}\"\n",
        "\n",
        "def evaluate_retrieval(query, relevant_docs, retrieved_docs, k=5):\n",
        "    # Calculate Precision@k, Recall@k, and F1 Score\n",
        "    relevant_set = set(relevant_docs)\n",
        "    retrieved_set = set(retrieved_docs[:k])\n",
        "\n",
        "    precision = len(relevant_set.intersection(retrieved_set)) / len(retrieved_set)\n",
        "    recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_generation(reference, generated):\n",
        "    # Calculate BLEU Score\n",
        "    smooth = SmoothingFunction().method4\n",
        "    bleu_score = sentence_bleu([reference.split()], generated.split(), smoothing_function=smooth)\n",
        "\n",
        "    # Calculate ROUGE Score\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(generated, reference)[0]\n",
        "\n",
        "    return bleu_score, rouge_scores\n",
        "\n",
        "def visualize_metrics(precision, recall, f1, bleu, rouge):\n",
        "    # Plot Precision, Recall, and F1 Score\n",
        "    metrics = {'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
        "    sns.barplot(x=list(metrics.keys()), y=list(metrics.values()))\n",
        "    plt.title('Retrieval Metrics')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot BLEU and ROUGE Scores\n",
        "    generation_metrics = {'BLEU Score': bleu, 'ROUGE-1': rouge['rouge-1']['f'], 'ROUGE-2': rouge['rouge-2']['f'], 'ROUGE-L': rouge['rouge-l']['f']}\n",
        "    sns.barplot(x=list(generation_metrics.keys()), y=list(generation_metrics.values()))\n",
        "    plt.title('Generation Metrics')\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    print(greet_user())\n",
        "    user_id = get_user_id()\n",
        "    plan_id = input(\"Please enter your plan ID: \")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"How can I assist you with your itinerary? \")\n",
        "        response = handle_user_request(user_input, user_id, plan_id)\n",
        "        print(response)\n",
        "\n",
        "        # Example evaluation (replace with actual data)\n",
        "        relevant_docs = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "        retrieved_docs = retrieve_documents(user_input, relevant_docs)\n",
        "        precision, recall, f1 = evaluate_retrieval(user_input, relevant_docs, retrieved_docs)\n",
        "\n",
        "        reference = \"This is a reference response.\"\n",
        "        bleu, rouge = evaluate_generation(reference, response)\n",
        "\n",
        "        visualize_metrics(precision, recall, f1, bleu, rouge)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        ""
      ]
    }
  ]
}